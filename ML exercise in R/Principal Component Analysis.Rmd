---
title: "9.2"
author: "Maninder Ade"
date: "02/26/2021"
output: pdf_document
---

#############################################
rm(list = ls())
install.packages("corrplot")
library(corrplot)
library(DAAG)
set.seed(1)

#############################################

# Load Data from the working directory
data <- read.table("uscrime.txt",header = TRUE, stringsAsFactors = FALSE)

head(data)

## Checking for multicollinearity - check the correlation matrix if values are greater than 0.9
cor_results <- cor(data)
corrplot(cor_results, method="number")
# Based on above matrix Po1 (per capita expenditure on police protection in 1960) and Po2 (per capita expenditure on police protection in 1959) are correlated

#Lets run PCA on Crime Data
pca <- prcomp(data[,1:15], scale=T)
summary(pca)

plot(pca$x[,1],pca$x[,2])
pca.var <- pca$sdev^2
pca.var.per <- round(pca.var/sum(pca.var)*100,1)
barplot(pca.var.per, main="Screen Plot", xlab = "Principle Component", ylab = "Percent Variation")

plot(cumsum(pca.var.per),main="Cumulative % Plot",xlab = "Principle Component", ylab = "Percent Variation", type="b")


#The main purpose of a scree plot is to graph the component analysis results as a scree plot and find where the obvious change in slope (elbow) occurs
screeplot(pca,main='Scree Plot (variance explained @5 is 86%)', type = "line")
abline(h=1)
# Based on scree plot PCs 5 is realistic with 86% of percent explained. To better understand, lets see how the model explains the variance using combination of R^2 values and later compare them with the cross validation.

R2_lm <- numeric(15)
R2_cvlm <- numeric(15)

for (i in 1:ncol(pca$x)){
pc_data <- cbind(data[,16],pca$x[,1:i])
model <- lm(V1~., as.data.frame(pc_data))
cv_model <- cv.lm(as.data.frame(pc_data),model,m=5)
R2_lm[i] = 1 - sum(model$residuals^2)/sum((data$Crime - mean(data$Crime))^2)
R2_cvlm[i] <- 1 - attr(cv_model,"ms")*nrow(data)/sum((data$Crime - mean(data$Crime))^2)
}

plot(1:ncol(pca$x), R2_lm, pch=19, xlab = "Principal Component",ylab = "R Squared Value", ylim = c(0,1), type = "b", col = "blue")
lines(1:ncol(pca$x), R2_cvlm, pch=18, type = "b", col = "red", lty=2)
legend("topright", inset=.02, legend = c("Basic lm", "Cross validated lm"), col=c("blue", "red"), lty=1:2, cex=0.8)

# R^2 values into excel 
df <- data.frame(R2_lm, R2_cvlm, 1:ncol(pca$x))
library("writexl")
write_xlsx(df,"\\R Squared Values.xlsx")

# Based on above observations; five principal compoenents is ideal to explain maximum variance, based on scree plot, cummulative % variance explained, basic lm R square values and cross validation  R square values.

# Linear regression model with 5 PCs
pc <- cbind(pca$x[,1:5],data[,16])
lm_model <- lm(V6~.,data=as.data.frame(pc))
summary(lm_model)
#Call:
#lm(formula = V6 ~ ., data = as.data.frame(pc))

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-420.79 -185.01   12.21  146.24  447.86 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      35.59  25.428  < 2e-16 ***
#PC1            65.22      14.67   4.447 6.51e-05 ***
#PC2           -70.08      21.49  -3.261  0.00224 ** 
#PC3            25.19      25.41   0.992  0.32725    
#PC4            69.45      33.37   2.081  0.04374 *  
#PC5          -229.04      36.75  -6.232 2.02e-07 ***
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 244 on 41 degrees of freedom
#Multiple R-squared:  0.6452,	Adjusted R-squared:  0.6019 
#F-statistic: 14.91 on 5 and 41 DF,  p-value: 2.446e-08

#Converting PCA coefficients to original format
c <- model$coefficients[1] #PCA intercept
coef <- model$coefficients[2:6] #PCA coefficients
scaledcoef <- pca$rotation[,1:5] %*% coef #coefficients of scaled data
a <- sapply(data[,1:15],mean)
b <- sapply(data[,1:15],sd)
unscaledcoef <- scaledcoef/b #unscaled coefficients
c_unscaled <- c - sum(scaledcoef*a/b) #unscaled intercept

# calculate estimates
est <- as.matrix(data[,1:15]) %*% unscaledcoef + c_unscaled

# calculate  sum of squared errors
sse = sum((est-data[,16])^2)
sstot = sum((data[,16]-mean(data[,16]))^2)

R2 <- 1-sse/sstot
R2_adj <- R2 - (1-R2)*5/(nrow(data)-5-1)

# Creating test data point to predict crime rate using the linear regression model
test_point <- data.frame(M = 14.0, So = 0, Ed = 10.0, Po1 = 12.0, Po2 = 15.5, LF = 0.640, M.F = 94.0, Pop = 150, NW = 1.1, U1 = 0.120, U2 = 3.6, Wealth = 3200, Ineq = 20.1, Prob = 0.04, Time = 39.0)

pred_pca <- data.frame(predict(pca,test_point)) # predict with pca data

pred <- predict(lm_model,pred_pca) #predict with 5 PCs linear model


 