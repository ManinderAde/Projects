---
title: "11.1"
author: "Maninder Ade"
date: "03/16/2021"
output: pdf_document
---

#############################################
rm(list = ls())
library(DAAG) ## for Cross validation
library(tree) ## for Regression tree
library(caret) ## for preprocessing the data
library(glmnet) ## for LASSO and Elastic net 
set.seed(1)

#############################################

# Load Data from the working directory
data <- read.table("uscrime.txt", stringsAsFactors = FALSE, header = TRUE)

head(data)

# Scale the data (column 2 is already in a binary data type)
s_data <- as.data.frame(scale(data[,-c(2,16)]))
s_data <- cbind(data[,2],s_data,data[,16])
colnames(s_data)[1] <- "So"
colnames(s_data)[16] <- "Crime"
head(s_data)

########### Step-wise Regression ###########
# trainControl generates parameters that further control how models are created; with repeatedcv total 6 fold cv repeated 3 times
ctrl_data <- trainControl(method = 'repeatedcv', number = 6, repeats = 3)
# default backward selection process adopted
lt_AIC <- train(Crime ~., data = s_data, method='lmStepAIC', scope = list(lower = Crime~1, upper = Crime~.),
               direction = "backward", trControl=ctrl_data)

# Final Model
lt_AIC$finalModel
lt_AIC$results

#Call:
#lm(formula = .outcome ~ M + Ed + Po1 + M.F + U1 + U2 + Ineq + 
#    Prob, data = dat)

#Coefficients:
#(Intercept)            M           Ed          Po1          M.F           U1  
#     905.09       117.28       201.50       305.07        65.83      -109.73  
#         U2         Ineq         Prob  
#     158.22       244.70       -86.31   

# Run the final model using linear regression and check the R^2 value
swb_model <- lm(formula = Crime ~ M + Ed + Po1 + M.F + U1 + U2 + Ineq + Prob , data = s_data)
summary(swb_model)

#Call:
#lm(formula = Crime ~ M + Ed + Po1 + M.F + U1 + U2 + Ineq + Prob, 
#    data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-444.70 -111.07    3.03  122.15  483.30 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      28.52  31.731  < 2e-16 ***
#M             117.28      42.10   2.786  0.00828 ** 
#Ed            201.50      59.02   3.414  0.00153 ** 
#Po1           305.07      46.14   6.613 8.26e-08 ***
#M.F            65.83      40.08   1.642  0.10874    
#U1           -109.73      60.20  -1.823  0.07622 .  
#U2            158.22      61.22   2.585  0.01371 *  
#Ineq          244.70      55.69   4.394 8.63e-05 ***
#Prob          -86.31      33.89  -2.547  0.01505 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 195.5 on 38 degrees of freedom
#Multiple R-squared:  0.7888,	Adjusted R-squared:  0.7444 
#F-statistic: 17.74 on 8 and 38 DF,  p-value: 1.159e-10

# Lets see the quality of the model
lm_predict <- predict(swb_model, data = s_data[,1:15])
RSS <- sum((lm_predict - s_data[,16])^2)
TSS <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2 <- 1 - RSS/TSS
R2
# 0.7888268

# M.F and U1 have p-value greater than 0.05, lets see the quality of the model without M.F and U1
swb_model2 <- lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq + Prob , data = s_data)
summary(swb_model2)

#Call:
#lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-470.68  -78.41  -19.68  133.12  556.23 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      29.27  30.918  < 2e-16 ***
#M             131.98      41.85   3.154  0.00305 ** 
#Ed            219.79      50.07   4.390 8.07e-05 ***
#Po1           341.84      40.87   8.363 2.56e-10 ***
#U2             75.47      34.55   2.185  0.03483 *  
#Ineq          269.91      55.60   4.855 1.88e-05 ***
#Prob          -86.44      34.74  -2.488  0.01711 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 200.7 on 40 degrees of freedom
#Multiple R-squared:  0.7659,	Adjusted R-squared:  0.7307 
#F-statistic: 21.81 on 6 and 40 DF,  p-value: 3.418e-11

# Lets see the quality of the model
lm_predict2 <- predict(swb_model2, data = s_data[,1:15])
RSS2 <- sum((lm_predict2 - s_data[,16])^2)
TSS2 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_2 <- 1 - RSS2/TSS2
R2_2
#0.7658663
#from the r^2 value it is evident that model variance explanation doesnt have much impact without M.F and U1 variables

########### LASSO Regression ###########
# for glmnet function the x need to be in R’s matrix format, rather than data frame format.
lasso_model <- cv.glmnet(x=as.matrix(s_data[,-16]),y=as.matrix(s_data$Crime),nfolds = 6, type.measure = "mse", family = "gaussian",alpha=1)
plot(lasso_model)

# The 𝜆min is the one which minimizes out-of-sample loss in CV. The 𝜆1se is the one which is the largest 𝜆 value within 1 standard error of 𝜆min. One line of reasoning suggests using 𝜆1𝑠𝑒 because it hedges against overfitting by selecting a larger 𝜆 value than the min.

coef(lasso_model, s=lasso_model$lambda.min) # 10 variables selected

#16 x 1 sparse Matrix of class "dgCMatrix"
                    
#(Intercept) 889.648601
#So           45.344736
#M            77.635868
#Ed           98.182711
#Po1         311.196426
#Po2           .       
#LF            2.887732
#M.F          46.955007
#Pop           .       
#NW            2.654767
#U1            .       
#U2           29.302470
#Wealth        .       
#Ineq        164.140537
#Prob        -77.051224
#Time          .       

# Run the final model using linear regression and check the R^2 value
lasso_lm_model <- lm(formula = Crime ~ So + M + Ed + Po1 + LF + M.F + NW + U2 + Ineq + Prob, data = s_data)
summary(lasso_lm_model)

#Call:
#lm(formula = Crime ~ So + M + Ed + Po1 + LF + M.F + NW + U2 + 
#    Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-410.55 -121.42    5.76  110.54  550.24 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)  863.284     53.510  16.133  < 2e-16 ***
#So           122.792    129.896   0.945  0.35080    
#M            113.614     49.962   2.274  0.02903 *  
#Ed           188.755     64.750   2.915  0.00608 ** 
#Po1          333.470     49.353   6.757 6.86e-08 ***
#LF            25.162     49.588   0.507  0.61496    
#M.F           31.513     43.179   0.730  0.47021    
#NW            -2.883     59.595  -0.048  0.96169    
#U2            72.881     41.795   1.744  0.08973 .  
#Ineq         229.121     68.845   3.328  0.00203 ** 
#Prob         -99.145     40.243  -2.464  0.01867 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 206.6 on 36 degrees of freedom
#Multiple R-squared:  0.7767,	Adjusted R-squared:  0.7147 
#F-statistic: 12.53 on 10 and 36 DF,  p-value: 5.374e-09

# Lets see the quality of the model
lasso_lm_predict <- predict(lasso_lm_model, data = s_data[,1:15])
RSS3 <- sum((lasso_lm_predict - s_data[,16])^2)
TSS3 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_3 <- 1 - RSS3/TSS3
R2_3
#0.7767478

# So, LF, M.F, NW and U2 have p-value greater than 0.05, lets see the quality of the model without those variables

lasso_lm_model2 <- lm(formula = Crime ~ M + Ed + Po1 + Ineq + Prob, data = s_data)
summary(lasso_lm_model2)

#Call:
#lm(formula = Crime ~ M + Ed + Po1 + Ineq + Prob, data = s_data)

#Residuals:
#   Min     1Q Median     3Q    Max 
#-528.2  -74.0   -7.0  139.8  503.3 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      30.59  29.587  < 2e-16 ***
#M             100.15      41.00   2.443 0.018964 *  
#Ed            179.16      48.58   3.688 0.000656 ***
#Po1           360.28      41.79   8.621 9.47e-11 ***
#Ineq          272.53      58.09   4.692 3.00e-05 ***
#Prob          -87.93      36.30  -2.422 0.019930 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 209.7 on 41 degrees of freedom
#Multiple R-squared:  0.7379,	Adjusted R-squared:  0.706 
#F-statistic: 23.09 on 5 and 41 DF,  p-value: 5.926e-11

# Lets see the quality of the model
lasso_lm_predict2 <- predict(lasso_lm_model2, data = s_data[,1:15])
RSS4 <- sum((lasso_lm_predict2 - s_data[,16])^2)
TSS4 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_4 <- 1 - RSS4/TSS4
R2_4
#0.7379292

########### Elastic Net ###########
# r-squared value for different values is developed
alpha <- seq(0.1,0.9,0.05)
r_squared <- c()
for (i in alpha){
elastic_net <- cv.glmnet(x=as.matrix(s_data[,-16]),y=as.matrix(s_data$Crime),nfolds = 6, type.measure = "mse", family = "gaussian",alpha=i)

r_squared <- cbind(r_squared, elastic_net$glmnet.fit$dev.ratio[which(elastic_net$glmnet.fit$lambda == elastic_net$lambda.min)])
}

plot(alpha, r_squared, type ="b")
# alpha best is observed at 0.35
# lets run model at alpha = 0.35
elastic_net1 <- cv.glmnet(x=as.matrix(s_data[,-16]),y=as.matrix(s_data$Crime),nfolds = 6, type.measure = "mse", family = "gaussian",alpha=0.35)

coef(elastic_net1, s=elastic_net1$lambda.min) # 13 variables selected

#16 x 1 sparse Matrix of class "dgCMatrix"
#(Intercept) 890.69826
#So           42.26137
#M            98.14612
#Ed          160.22979
#Po1         245.40554
#Po2          38.10893
#LF            .      
#M.F          61.41242
#Pop         -11.14222
#NW           20.30536
#U1          -69.67132
#U2          110.03643
#Wealth       49.30331
#Ineq        223.96484
#Prob        -90.48843
#Time          .      

# Run the final model using linear regression and check the R^2 value
en_lm_model <- lm(formula = Crime ~ So + M + Ed + Po1 + Po2 + M.F + Pop + NW + U1 + U2 + Wealth + Ineq + Prob, data = s_data)
summary(en_lm_model)

#Call:
#lm(formula = Crime ~ So + M + Ed + Po1 + Po2 + M.F + Pop + NW + 
#    U1 + U2 + Wealth + Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-389.63  -94.25    7.83  109.20  491.62 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   893.38      52.51  17.012  < 2e-16 ***
#So             34.40     127.12   0.271  0.78840    
#M             109.87      49.82   2.205  0.03451 *  
#Ed            202.41      64.00   3.163  0.00335 ** 
#Po1           501.63     287.30   1.746  0.09012 .  
#Po2          -215.08     288.65  -0.745  0.46148    
#M.F            43.45      48.99   0.887  0.38162    
#Pop           -36.21      46.10  -0.785  0.43784    
#NW             24.91      58.61   0.425  0.67360    
#U1            -86.62      66.24  -1.308  0.20002    
#U2            136.97      67.41   2.032  0.05027 .  
#Wealth         82.03      96.17   0.853  0.39983    
#Ineq          275.77      86.79   3.177  0.00322 ** 
#Prob          -95.16      41.52  -2.292  0.02843 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 204 on 33 degrees of freedom
#Multiple R-squared:  0.8005,	Adjusted R-squared:  0.7219 
#F-statistic: 10.19 on 13 and 33 DF,  p-value: 4.088e-08

# Lets see the quality of the model
en_lm_predict <- predict(en_lm_model, data = s_data[,1:15])
RSS4 <- sum((en_lm_predict - s_data[,16])^2)
TSS4 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_4 <- 1 - RSS4/TSS4
R2_4
#.8004917

# So, Po1, Po2, M.F, Pop, NW, U1, Wealth have p-value greater than 0.05, lets see the quality of the model without those variables

en_lm_model2 <- lm(formula = Crime ~ M + Ed + Ineq + Prob, data = s_data)
summary(en_lm_model2)

#Call:
#lm(formula = Crime ~ M + Ed + Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-532.97 -254.03  -55.72  137.80  960.21 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      50.69  17.856  < 2e-16 ***
#M              45.21      67.10   0.674  0.50417    
#Ed            166.24      80.45   2.066  0.04499 *  
#Ineq          107.22      90.85   1.180  0.24458    
#Prob         -166.71      58.21  -2.864  0.00651 ** 
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 347.5 on 42 degrees of freedom
#Multiple R-squared:  0.2629,	Adjusted R-squared:  0.1927 
#F-statistic: 3.745 on 4 and 42 DF,  p-value: 0.01077

# Lets see the quality of the model
en_lm_predict2 <- predict(en_lm_model2, data = s_data[,1:15])
RSS5 <- sum((en_lm_predict2 - s_data[,16])^2)
TSS5 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_5 <- 1 - RSS5/TSS5
R2_5
#0.2629093

###########################################################

# alpha best is observed at 0.55
# lets run model at alpha = 0.55
elastic_net2 <- cv.glmnet(x=as.matrix(s_data[,-16]),y=as.matrix(s_data$Crime),nfolds = 6, type.measure = "mse", family = "gaussian",alpha=0.55)

coef(elastic_net2, s=elastic_net2$lambda.min) # 12 variables selected

#16 x 1 sparse Matrix of class "dgCMatrix"
#(Intercept) 891.56781
#So           39.70706
#M            99.42545
#Ed          164.79190
#Po1         287.81207
#Po2           .      
#LF            .      
#M.F          57.68551
#Pop         -12.52834
#NW           17.95933
#U1          -68.01310
#U2          109.56483
#Wealth       47.37076
#Ineq        229.28512
#Prob        -89.71634
#Time          .      

# Run the final model using linear regression and check the R^2 value
en_lm_model3 <- lm(formula = Crime ~ So + M + Ed + Po1 + M.F + Pop + NW + U1 + U2 + Wealth + Ineq + Prob, data = s_data)
summary(en_lm_model3)

#Call:
#lm(formula = Crime ~ So + M + Ed + Po1 + M.F + Pop + NW + U1 + 
#    U2 + Wealth + Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-434.18 -107.01   18.55  115.88  470.32 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   897.29      51.91  17.286  < 2e-16 ***
#So             22.89     125.35   0.183  0.85621    
#M             112.71      49.35   2.284  0.02876 *  
#Ed            195.70      62.94   3.109  0.00378 ** 
#Po1           293.18      64.99   4.511 7.32e-05 ***
#M.F            48.92      48.12   1.017  0.31656    
#Pop           -33.25      45.63  -0.729  0.47113    
#NW             19.16      57.71   0.332  0.74195    
#U1            -89.76      65.68  -1.367  0.18069    
#U2            140.78      66.77   2.108  0.04245 *  
#Wealth         83.30      95.53   0.872  0.38932    
#Ineq          285.77      85.19   3.355  0.00196 ** 
#Prob          -92.75      41.12  -2.255  0.03065 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 202.6 on 34 degrees of freedom
#Multiple R-squared:  0.7971,	Adjusted R-squared:  0.7255 
#F-statistic: 11.13 on 12 and 34 DF,  p-value: 1.52e-08

# Lets see the quality of the model
en_lm_predict3 <- predict(en_lm_model3, data = s_data[,1:15])
RSS6 <- sum((en_lm_predict3 - s_data[,16])^2)
TSS6 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_6 <- 1 - RSS6/TSS6
R2_6
#0.7971352

# So, M.F, Pop, NW, U1, Wealth have p-value greater than 0.05, lets see the quality of the model without those variables

en_lm_model4 <- lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq + Prob, data = s_data)
summary(en_lm_model4)

#Call:
#lm(formula = Crime ~ M + Ed + Po1 + U2 + Ineq + Prob, data = s_data)

#Residuals:
#    Min      1Q  Median      3Q     Max 
#-470.68  -78.41  -19.68  133.12  556.23 

#Coefficients:
#            Estimate Std. Error t value Pr(>|t|)    
#(Intercept)   905.09      29.27  30.918  < 2e-16 ***
#M             131.98      41.85   3.154  0.00305 ** 
#Ed            219.79      50.07   4.390 8.07e-05 ***
#Po1           341.84      40.87   8.363 2.56e-10 ***
#U2             75.47      34.55   2.185  0.03483 *  
#Ineq          269.91      55.60   4.855 1.88e-05 ***
#Prob          -86.44      34.74  -2.488  0.01711 *  
#---
#Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

#Residual standard error: 200.7 on 40 degrees of freedom
#Multiple R-squared:  0.7659,	Adjusted R-squared:  0.7307 
#F-statistic: 21.81 on 6 and 40 DF,  p-value: 3.418e-11

# Lets see the quality of the model
en_lm_predict7 <- predict(en_lm_model4, data = s_data[,1:15])
RSS7 <- sum((en_lm_predict7 - s_data[,16])^2)
TSS7 <- sum((s_data[,16] - mean(s_data[,16]))^2)
R2_7 <- 1 - RSS7/TSS7
R2_7
#0.7658663